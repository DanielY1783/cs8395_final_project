{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-GlUJTblpVwI"
   },
   "source": [
    "Original Notebook from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n",
    "\n",
    "Modified by Daniel Yan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7wNjDKdQy35h"
   },
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "TRm-USlsHgEV",
    "outputId": "c22fcf93-eb7d-47ee-d3b1-92cae559c9d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'pytorch-CycleGAN-and-pix2pix'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pt3igws3eiVp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('pytorch-CycleGAN-and-pix2pix/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "colab_type": "code",
    "id": "z1EySlOXwwoa",
    "outputId": "a3a3fde0-7cbe-4ecc-e285-4b56228f0a43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=0.4.1 in f:\\programs\\anaconda\\envs\\python36\\lib\\site-packages (from -r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: torchvision>=0.2.1 in f:\\programs\\anaconda\\envs\\python36\\lib\\site-packages (from -r requirements.txt (line 2)) (0.4.2)\n",
      "Collecting dominate>=2.3.1\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/e6/794a119963b7cfe4bd41177c8f9d4195fe901652f04189fbd2edf513c7b2/dominate-2.5.1-py2.py3-none-any.whl\n",
      "Collecting visdom>=0.1.8.3\n",
      "  Downloading https://files.pythonhosted.org/packages/c9/75/e078f5a2e1df7e0d3044749089fc2823e62d029cc027ed8ae5d71fafcbdc/visdom-0.1.8.9.tar.gz (676kB)\n",
      "Requirement already satisfied: numpy in f:\\programs\\anaconda\\envs\\python36\\lib\\site-packages (from torch>=0.4.1->-r requirements.txt (line 1)) (1.17.3)\n",
      "Requirement already satisfied: six in f:\\programs\\anaconda\\envs\\python36\\lib\\site-packages (from torchvision>=0.2.1->-r requirements.txt (line 2)) (1.13.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in f:\\programs\\anaconda\\envs\\python36\\lib\\site-packages (from torchvision>=0.2.1->-r requirements.txt (line 2)) (6.2.1)\n",
      "Requirement already satisfied: scipy in f:\\programs\\anaconda\\envs\\python36\\lib\\site-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (1.3.1)\n",
      "Requirement already satisfied: requests in f:\\programs\\anaconda\\envs\\python36\\lib\\site-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (2.23.0)\n",
      "Requirement already satisfied: tornado in f:\\programs\\anaconda\\envs\\python36\\lib\\site-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (6.0.3)\n",
      "Requirement already satisfied: pyzmq in f:\\programs\\anaconda\\envs\\python36\\lib\\site-packages (from visdom>=0.1.8.3->-r requirements.txt (line 4)) (18.1.1)\n",
      "Collecting jsonpatch\n",
      "  Downloading https://files.pythonhosted.org/packages/82/53/73ca86f2a680c705dcd1708be4887c559dfe9ed250486dd3ccd8821b8ccb/jsonpatch-1.25-py2.py3-none-any.whl\n",
      "Collecting torchfile\n",
      "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
      "Collecting websocket-client\n",
      "  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\programs\\anaconda\\envs\\python36\\lib\\site-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in f:\\programs\\anaconda\\envs\\python36\\lib\\site-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in f:\\programs\\anaconda\\envs\\python36\\lib\\site-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in f:\\programs\\anaconda\\envs\\python36\\lib\\site-packages (from requests->visdom>=0.1.8.3->-r requirements.txt (line 4)) (3.0.4)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Downloading https://files.pythonhosted.org/packages/18/b0/a80d29577c08eea401659254dfaed87f1af45272899e1812d7e01b679bc5/jsonpointer-2.0-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: visdom, torchfile\n",
      "  Building wheel for visdom (setup.py): started\n",
      "  Building wheel for visdom (setup.py): finished with status 'done'\n",
      "  Created wheel for visdom: filename=visdom-0.1.8.9-cp36-none-any.whl size=655256 sha256=0e858cc3bb7be3f20c213d552b726d4794867a353228805ae8b351c5359f1d59\n",
      "  Stored in directory: C:\\Users\\Daniel\\AppData\\Local\\pip\\Cache\\wheels\\70\\19\\a7\\6d589ed967f4dfefd33bc166d081257bd4ed0cb618dccfd62a\n",
      "  Building wheel for torchfile (setup.py): started\n",
      "  Building wheel for torchfile (setup.py): finished with status 'done'\n",
      "  Created wheel for torchfile: filename=torchfile-0.1.0-cp36-none-any.whl size=5717 sha256=8ac4e147c578345ab9da207a9395be63c4a6a54bd6d859265bf2de37adceef73\n",
      "  Stored in directory: C:\\Users\\Daniel\\AppData\\Local\\pip\\Cache\\wheels\\b1\\c3\\d6\\9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
      "Successfully built visdom torchfile\n",
      "Installing collected packages: dominate, jsonpointer, jsonpatch, torchfile, websocket-client, visdom\n",
      "Successfully installed dominate-2.5.1 jsonpatch-1.25 jsonpointer-2.0 torchfile-0.1.0 visdom-0.1.8.9 websocket-client-0.57.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoints directory\n",
    "!mkdir checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Steps\n",
    "- Move the model to the checkpoints directory (if not there already) and name the model to test \"latest_net_D.pth\" and \"latest_net_G.pth\"\n",
    "\n",
    "- Create a directory called \"results\" to store the results to\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9UkcaFZiyASl"
   },
   "source": [
    "# Testing\n",
    "\n",
    "-   `python test.py --dataroot ./datasets/facades --direction BtoA --model pix2pix --name facades_pix2pix`\n",
    "\n",
    "Change the `--dataroot`, `--name`, and `--direction` to be consistent with your trained model's configuration and how you want to transform images.\n",
    "\n",
    "> from https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix:\n",
    "> Note that we specified --direction BtoA as Facades dataset's A to B direction is photos to labels.\n",
    "\n",
    "> If you would like to apply a pre-trained model to a collection of input images (rather than image pairs), please use --model test option. See ./scripts/test_single.sh for how to apply a model to Facade label maps (stored in the directory facades/testB).\n",
    "\n",
    "> See a list of currently available models at ./scripts/download_pix2pix_model.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uCsKkEq0yGh0",
    "outputId": "e50db50e-08f7-45fa-cfc0-c97bcbf62431"
   },
   "outputs": [],
   "source": [
    "# Generate the actual images\n",
    "!python test.py --dataroot generated_segmentation_2d --direction AtoB --model pix2pix --name seg_pix2pixBtoA --results_dir results --num_test 15190"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n",
      "fake_B.png\n"
     ]
    }
   ],
   "source": [
    "# Filter for only the generated images\n",
    "IMG_DIR = \"results/seg_pix2pixBtoA/test_latest/images/\"\n",
    "for filename in os.listdir(IMG_DIR):\n",
    "    # Get the last ten characters of the file name\n",
    "    end = filename[-10:]\n",
    "    # If the last ten are equal to \"fake_B.png\", rename file to remove ending. Otherwise, delete file.\n",
    "    if end == \"fake_B.png\":\n",
    "        os.rename(IMG_DIR + filename, IMG_DIR + filename[:-10] + \".png\")\n",
    "    else:\n",
    "        os.remove(IMG_DIR + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OzSKIPUByfiN"
   },
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Mgg8raPyizq"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_fake_B.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0G3oVH9DyqLQ"
   },
   "outputs": [],
   "source": [
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_A.png')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ErK5OC1j1LH4"
   },
   "outputs": [],
   "source": [
    "img = plt.imread('./results/facades_label2photo_pretrained/test_latest/images/100_real_B.png')\n",
    "plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "pix2pix_modified",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
